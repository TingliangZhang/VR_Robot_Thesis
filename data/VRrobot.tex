\chapter{项目背景}

目前人工智能尚不能执行多数场景的复杂任务，特别是抢险救灾等需要随机应变的任务，需要遥操作机器人。目前机器人远程控制普遍采用手柄或键盘控制方式，且监控方式普遍为摄像头图像显示在监视器上，与现场操作差别很大。

//插图

现有的基于动作捕捉的遥操作系统如OptiTrack和机械外骨骼等，虽然体验还好，但是成本极高，依赖性强，无法大规模应用。现有的实时VR显示大多基于图像拼接，图像采集设备昂贵，实时性和图像质量无法同时兼顾，且对算力要求很高。

本作品提出了一种廉价，低延时的遥操作系统，其双目摄像头及VR显示系统可使操作者看到具有立体感的实时画面，手持追踪器操作机械臂末端符合人类日常使用手进行操作的习惯，可以给予操作者以身临其境的操作体验。




\chapter{现有系统问题}

\section{现有的三维图像采集系统}
目前较成熟的实时三维场景采集系统基本上都基于图像拼接技术：

要创建一个360度的视频，无论是使用一组特殊的摄像机同时记录360度的场景，还是将4个不同角度的GoPros图像拼接在一起。传入的360度视频文件是4K和更高，比特率可以超过50 Mb/s。而用于VR的3D 360度视频是其两倍，即每小时44 GB视频。如果要实时发送和接收这些图像信息，对带宽等网络环境要求非常高。另外无论采用立方体还是金字塔形拼接方式，拼接这些图像会消耗大量的算力，运算和传输延迟加起来都会达到2s以上，实时性和图像质量无法同时兼顾。

如Google Jump


\section{现有的机器人遥操作系统}
\subsection{不自然}
手柄，指令
\subsection{造价昂贵}

\subsection{依赖性}

\subsection{}


\chapter{系统简介}
本作品旨在解决以上系统的问题。

	该项目可分为两个子系统：图像显示系统及机器人控制系统。
	\section{图像显示系统}
	本项目旨在提供一个具有较强立体感的实时全景图像，以使远程操控者获得身临其境的体验。而由于实时全景图像拼接技术不成熟且耗费计算资源，此外三维场景的重构需要很高的算力且不能保证实时性，因此我们选择了较为便捷、高效的方法，即用ZED双目摄像头来采集实时场景信息。两个目采集到的图像对应到VR眼镜的两个显示屏中，而搭载ZED的多自由度支架可随操纵者头部的转动而实时旋转，以保证双目摄像头的朝向和操作者双眼朝向一致，从而使操作者可以实时地看到各方位的立体场景，同时也减小了延迟。
	\section{机器人控制系统}
	采用Vive追踪器进行远程控制，使得操作者能够利用自身的动作控制机器人的运动。这种方式高效、便捷、十分符合人类的行为习惯，因而会带来良好的操作体验。具体来讲，就是将多个Vive追踪器绑在操作者的各身体部位上，利用虚拟现实头盔和追踪器上的红外定位模块实时采集其各部位的位置和角度，而机器人终端则利用这些坐标和角度而精确重现操纵者的动作，进行各种任务。





\chapter{技术细节}

\section{实时图像采集与显示系统}
项目用于和Vive头盔进行互动的是一个ZED双目摄像头。ZED双目摄像头搭载在由两个数字舵机组成的双自由度平台上，用于与用户交互。

整个系统放置在4轮全向轮底盘上面， ZED双目摄像头采集到的图像，通过USB3.0发送给Nvidia Jetson TX1，TX1上运行Ubuntu，图像在TX1上处理后，使用UV4L服务（User space Video4Linux）发送到局域网。同时，Vive VR头盔的姿态数据通过HTC串流盒发送到计算机中进行处理，处理后通过蓝牙串口发送到全向轮车上面的Arduino Mega 2560，控制双自由度数字舵机做出与Vive VR头盔同步的转动，使安装在双自由度数字舵机平台上的ZED双目摄像头的指向与Vive头盔实时相同。

演示视频参见附件XXX

\section{机械臂控制系统}

\section{NAO机器人控制系统}
项目中为了控制机器人的手臂，采用逆运动学的方式，通过设定机器人的通过设定机器人的端点来计算关节必要的旋转值以计划动作。由于NAO机器人手臂（不包括手指部分）的自由度超过3个，因此在仅要设置手指尖端的目标坐标点的情况下，会出现手臂姿态不唯一的情况。通过筛选使得手臂各个关节与端点的坐标实现一一对应。
对于机器人的姿态设定、端点设定涉及到机器人的控制理论，主要为为每个关节建立标准坐标系解读链接和位置以及决定关节转换的基本程序。从操控熬点开始到第一个关节，再以此类推直到最后一个关节。转换后得到的转换矩阵可以用来得到目标位置。

我们主要采用Denavit Hartenberg (DH)来进行运动学的计算。我们根据厂家提供的四个标准练习所得到的四个矩阵相乘可以得到变换矩阵A。每个n代表现在的关节，整理后如下所示：

为了根据目的点的坐标分离方程序，以得到各个关节的值，我们将变换矩阵"An"的逆矩阵相乘于关系方程序的左边来取得计算角度值的元素。右手包含五个关节，从上到下分别是肩膀关节(RShoulderPitch，RShoulderRoll 两个)，手肘关节(elbow RElbowRoll，RElbowYaw 两个)，和手腕关节(RWristYaw)。因此，表示从肩膀到手腕的移动的转动矩阵为

然后我们通过逐步乘以的方式得到各个关节的变换矩阵A，进而可以通过以下公式得到每个关节的转动参数。

由以上方程并结合NAO的链接关节变量数据（在NAO官网上提供），我们可以根据目的点得到每个关节点旋转的角度，从而达到基于逆运动学控制机器人的机械臂。



\chapter{项目展示}

现阶段已完成一个由全向轮底盘移动的机械臂，平台上搭载多自由度机械结构托举的双目摄像头，随着操作者头部的转动而同步转动，以采集实时图像信息。

我们可以实现读取追踪器和VR头盔绝对位置并通过串口发送。可以看到图片中输出了左手，右手和头盔的绝对坐标。我们改写了机械臂底层及接口，解决了串口控制卡顿的情况。现在已实现用遥控器-接收机控制系统，远程完成叠纸杯实验。另外，我们在机械臂末端加上了吸盘执行机构，使用气泵和电磁阀组建了一个吸附装置。四轮全向轮底盘也搭建完成。

经测试，我们这套系统远程控制实时性很好，视频传输感受不到延迟，在VR眼睛中有很强的立体感。此外，控制较传统方式更简便，追踪器较外骨骼造价低。

在之后的一段时间内，我们将调用追踪器位置信息，发送给下位机，实现追踪器控制机械臂的功能。

另外我们刚刚借到了Now机器人，准备在操作者手脚上放置四个追踪器，以此来控制机器人的运动，如站立，行走等。


\section{}

\section{}



\chapter{未来应用}
未来此技术可以用于拆弹，救援，远程交互等领域。为了完善机器人的功能，可以加上手势识别元件实现机器人手部的动作。

此外，该系统中机器人可不断对操控者的行为进行学习。通过采集每次操作的数据，可以使用增强学习训练机器人自主地执行任务。
